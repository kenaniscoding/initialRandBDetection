{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "\n",
    "# Constants\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMG_SIZE = 224\n",
    "RESNET_MODEL_PATH = \"resnet_fruit_model.pth\"  # Path to the trained ResNet model\n",
    "EFFICIENTNET_MODEL_PATH = \"efficientnet_fruit_model.pth\"  # Path to the trained EfficientNet model\n",
    "\n",
    "# Classes\n",
    "FRUIT_CLASSES = [\"1. Green\", \"1. Ripe\", \"1. Semi-Ripe\", \"2. Green Defect\", \"2. Ripe Defect\", \"2. Semi-Ripe Defect\"]\n",
    "BRUISED_CLASSES = [\"Not Bruised\", \"Bruised\"]\n",
    "\n",
    "# Preprocessing transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),   \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model definition (same for both models)\n",
    "class MultiTaskClassifier(nn.Module):\n",
    "    def __init__(self, base_model, num_classes, bruised_classes, model_type=\"resnet\"):\n",
    "        super(MultiTaskClassifier, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.model_type = model_type\n",
    "\n",
    "        # Determine the number of input features based on the model type\n",
    "        if model_type == \"resnet\":\n",
    "            in_features = self.base_model.fc.in_features\n",
    "            # Replace the fc layer with an Identity layer\n",
    "            self.base_model.fc = nn.Identity()\n",
    "        elif model_type == \"efficientnet\":\n",
    "            in_features = self.base_model.classifier[1].in_features\n",
    "            # Replace the classifier layer with an Identity layer\n",
    "            self.base_model.classifier = nn.Identity()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "\n",
    "        # Define new classification layers\n",
    "        self.classifier = nn.Linear(in_features, num_classes)\n",
    "        self.bruised_classifier = nn.Linear(in_features, bruised_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)  # Feature extraction\n",
    "        fruit_class = self.classifier(x)  # Fruit and freshness classification\n",
    "        bruised_class = self.bruised_classifier(x)  # Bruised/Not Bruised classification\n",
    "        return fruit_class, bruised_class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load ResNet model\n",
    "resnet_model = MultiTaskClassifier(models.resnet50(weights=models.ResNet50_Weights.DEFAULT), \n",
    "                                   len(FRUIT_CLASSES), len(BRUISED_CLASSES), model_type=\"resnet\").to(DEVICE)\n",
    "resnet_model.load_state_dict(torch.load(RESNET_MODEL_PATH))\n",
    "resnet_model.eval()\n",
    "\n",
    "# Load EfficientNet model\n",
    "efficientnet_model = MultiTaskClassifier(models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT), \n",
    "                                         len(FRUIT_CLASSES), len(BRUISED_CLASSES), model_type=\"efficientnet\").to(DEVICE)\n",
    "efficientnet_model.load_state_dict(torch.load(EFFICIENTNET_MODEL_PATH))\n",
    "efficientnet_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef count_fruits(frame):\\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\\n    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\\n    _, thresh = cv2.threshold(blurred, 50, 255, cv2.THRESH_BINARY_INV)\\n    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\\n    return len(contours)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Fruit counter\n",
    "\"\"\"\n",
    "def count_fruits(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    _, thresh = cv2.threshold(blurred, 50, 255, cv2.THRESH_BINARY_INV)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return len(contours)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inference function\n",
    "def inference_window(model, window_name):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Fruit Count\n",
    "        # num_fruits = count_fruits(frame)\n",
    "\n",
    "        # Classification\n",
    "        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        img_tensor = transform(img).unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            fruit_pred, bruised_pred = model(img_tensor)\n",
    "            fruit_class = torch.argmax(fruit_pred, dim=1).item()\n",
    "            bruised_class = torch.argmax(bruised_pred, dim=1).item()\n",
    "\n",
    "        # Get classifications\n",
    "        fruit_name = FRUIT_CLASSES[fruit_class]\n",
    "        bruise_status = BRUISED_CLASSES[bruised_class]\n",
    "\n",
    "        # Display Results\n",
    "        # cv2.putText(frame, f\"Fruits Detected: {num_fruits}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "        cv2.putText(frame, f\"Bruised: {bruise_status}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "        cv2.putText(frame, f\"Type: {fruit_name}\", \n",
    "                    (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "        cv2.imshow(window_name, frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run inference for ResNet\n",
    "print(\"Starting ResNet inference...\")\n",
    "inference_window(resnet_model, \"ResNet Fruit Detector\")\n",
    "\n",
    "# Run inference for EfficientNet\n",
    "print(\"Starting EfficientNet inference...\")\n",
    "inference_window(efficientnet_model, \"EfficientNet Fruit Detector\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NvidiaEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
